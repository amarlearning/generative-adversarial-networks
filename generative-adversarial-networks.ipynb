{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gzip\nimport pickle\nimport sys, os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Any results you write to the current directory are saved as output.\nfrom keras.datasets import mnist","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N, W, H = x_train.shape\nD = W * H\nx_test = x_test.reshape(-1, D)\nx_train = x_train.reshape(-1, D)\n\nassert(len(x_test) == len(y_test))\nassert(len(x_train) == len(y_train))\n\nprint(\"No of training examples: \", len(x_train))\nprint(\"shape of training examples: \", x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# not sure about this\nlatent_dim = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the generator model\ndef build_generator(latent_dim):\n    i = Input(shape=(latent_dim,))\n    x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n    x = BatchNormalization(momentum=0.7)(x)\n    x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n    x = BatchNormalization(momentum=0.7)(x)\n    x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n    x = BatchNormalization(momentum=0.7)(x)\n    x = Dense(D, activation='tanh')(x)\n    model = Model(i, x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator(img_size):\n    i = Input(shape=(img_size,))\n    x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n    x = BatchNormalization(momentum=0.7)(x)\n    x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n    x = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(i, x)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build and compile the discriminator\nd_model = build_discriminator(D)\nd_model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(0.0002, 0.5),\n    metrics=['accuracy'])\n\n# Build and compile the combined model\ng_model = build_generator(latent_dim)\n\n# Create an input to represent noise sample from latent space\nz = Input(shape=(latent_dim,))\n\n# Pass noise through generator to get an image\nimg = g_model(z)\n\n# Make sure only the generator is trained\nd_model.trainable = False\n\n# The true output is fake, but we label them real!\nfake_pred = d_model(img)\n\n# Create the combined model object\ncombined_model = Model(z, fake_pred)\n\n# Compile the combined model\ncombined_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_losses = []\ng_losses = []\n\nepochs = 20000\nbatch_size = 32\nsample_period = 2000\n\nones = np.ones(batch_size)\nzeros = np.zeros(batch_size)\n\nif not os.path.exists('gan_images'):\n    os.makedirs('gan_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# record images after sample period\ndef sample_images(epoch):\n    rows, cols = 5, 5\n    noise = np.random.randn(rows * cols, latent_dim)\n    assert(noise.shape == (25, latent_dim))\n    imgs = g_model.predict(noise)\n\n    # Rescale images 0 - 1\n    imgs = 0.5 * imgs + 0.5\n\n    fig, axs = plt.subplots(rows, cols)\n    idx = 0\n    for i in range(rows):\n        for j in range(cols):\n            axs[i,j].imshow(imgs[idx].reshape(H, W), cmap='gray')\n            axs[i,j].axis('off')\n            idx += 1\n    fig.savefig(\"gan_images/%d.png\" % epoch)\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(epochs):\n    \n    ###########################\n    ### Train discriminator ###\n    ###########################\n    \n    d_model.trainable = True\n    \n    # Select a random batch of images\n    idx = np.random.randint(0, x_train.shape[0], batch_size)\n    real_imgs = x_train[idx]\n    \n    # Generate fake images\n    noise = np.random.randn(batch_size, latent_dim)\n    fake_imgs = g_model.predict(noise)    \n\n    # Train the discriminator\n    # both loss and accuracy are returned\n    d_loss_real, d_acc_real = d_model.train_on_batch(real_imgs, ones)\n    d_loss_fake, d_acc_fake = d_model.train_on_batch(fake_imgs, zeros)\n    \n    d_loss = 0.5 * (d_loss_real + d_loss_fake)\n    d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n    \n    ###########################\n    ##### Train generator #####\n    ###########################\n    d_model.trainable = False\n    \n    noise = np.random.randn(batch_size, latent_dim)\n    g_loss = combined_model.train_on_batch(noise, ones)\n    \n    # do it again!\n    noise = np.random.randn(batch_size, latent_dim)\n    g_loss = combined_model.train_on_batch(noise, ones)\n    \n    # why not one more time!\n    noise = np.random.randn(batch_size, latent_dim)\n    g_loss = combined_model.train_on_batch(noise, ones)\n\n    # Save the losses\n    d_losses.append(d_loss)\n    g_losses.append(g_loss)\n    \n    if epoch % 500 == 0:\n        print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f},  d_acc: {d_acc:.2f},  g_loss: {g_loss:.2f}\")\n        \n    if epoch % sample_period == 0:\n        sample_images(epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_images(epoch+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(g_losses, label='g_losses')\nplt.plot(d_losses, label='d_losses')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.io import imread\na = imread('gan_images/0.png')\nplt.imshow(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = imread('gan_images/2000.png')\nplt.imshow(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = imread('gan_images/4000.png')\nplt.imshow(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = imread('gan_images/18000.png')\nplt.imshow(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = imread('gan_images/20000.png')\nplt.imshow(a)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}